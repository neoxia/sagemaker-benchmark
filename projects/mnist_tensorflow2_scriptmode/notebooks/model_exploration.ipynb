{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is just used to make sure that the model can be run in the pipeline before running the pipeline !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\").\n",
    "# You may not use this file except in compliance with the License.\n",
    "# A copy of the License is located at\n",
    "#\n",
    "#     https://aws.amazon.com/apache-2-0/\n",
    "#\n",
    "# or in the \"license\" file accompanying this file. This file is distributed\n",
    "# on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
    "# express or implied. See the License for the specific language governing\n",
    "# permissions and limitations under the License.\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Input, Conv2D, MaxPool2D, BatchNormalization, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "def keras_model_fn(hyperparameters):\n",
    "    \"\"\"keras_model_fn receives hyperparameters from the training job and returns a compiled keras model.\n",
    "    The model is transformed into a TensorFlow Estimator before training and saved in a\n",
    "    TensorFlow Serving SavedModel at the end of training.\n",
    "    \"\"\"\n",
    "    _input = Input(shape=eval(hyperparameters[\"input_shape\"]))\n",
    "    x = _input\n",
    "    # cnn step\n",
    "    for _cnn in hyperparameters[\"cnn\"]:\n",
    "        x = Conv2D(_cnn[\"filters\"], eval(_cnn[\"kernel\"]), activation=_cnn[\"activation\"], padding=_cnn[\"padding\"],\n",
    "                   kernel_regularizer=l2(hyperparameters[\"l2_regul\"]), bias_regularizer=l2(hyperparameters[\"l2_regul\"]))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPool2D((2, 2))(x)\n",
    "    # dense step\n",
    "    x = Flatten()(x)\n",
    "    for _dense in hyperparameters[\"dense\"]:\n",
    "        x = Dense(_dense[\"units\"], activation=_dense[\"activation\"],\n",
    "                 kernel_regularizer=l2(hyperparameters[\"l2_regul\"]), bias_regularizer=l2(hyperparameters[\"l2_regul\"]))(x)\n",
    "        x = Dropout(hyperparameters[\"dropout\"])(x)\n",
    "    _output = Dense(hyperparameters[\"num_classes\"], activation=\"softmax\")(x)\n",
    "    \n",
    "    # generate the model\n",
    "    model = Model(inputs=_input, outputs=_output)\n",
    "    \n",
    "    print(model.summary())\n",
    "\n",
    "    # optimizer choice\n",
    "    if hyperparameters[\"optimizer\"].lower() == \"sgd\":\n",
    "        opt = SGD(lr=hyperparameters[\"learning_rate\"], decay=hyperparameters[\"weight_decay\"], momentum=hyperparameters[\"momentum\"])\n",
    "    elif hyperparameters[\"optimizer\"].lower() == \"rmsprop\":\n",
    "        opt = RMSprop(lr=hyperparameters[\"learning_rate\"], decay=hyperparameters[\"weight_decay\"])\n",
    "    else:\n",
    "        opt = Adam(lr=hyperparameters[\"learning_rate\"], decay=hyperparameters[\"weight_decay\"])\n",
    "            \n",
    "    # compile the model\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  optimizer=opt,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_shape': '(28, 28, 1)', 'num_classes': 10, 'epochs': 2, 'batch_size': 64, 'learning_rate': 0.001, 'optimizer': 'adam', 'momentum': 0.9, 'weight_decay': 0.01, 'l2_regul': 0.01, 'dropout': 0.1, 'cnn': [{'filters': 32, 'kernel': '(3, 3)', 'activation': 'relu', 'padding': 'same'}, {'filters': 32, 'kernel': '(3, 3)', 'activation': 'relu', 'padding': 'same'}], 'dense': [{'units': 128, 'activation': 'relu'}]}\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = json.load(open(\"../pipeline/hyperparameters.json\", \"r\"))\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               200832    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 211,946\n",
      "Trainable params: 211,818\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras_model_fn(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[0.10145849, 0.10281526, 0.09943226, 0.11487889, 0.09337983,\n",
       "        0.10688938, 0.09324344, 0.08578034, 0.10605171, 0.09607042]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "model(np.ones(shape=(1, 28, 28, 1), dtype=np.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
